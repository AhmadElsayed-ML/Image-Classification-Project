{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmrku0g6lAM4h3ZxWKgu4b"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEUKWlGa_ed0"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import scipy.io as sio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#distribue the data in training and testing\n",
        "(training_images, training_labels), (testing_images, testing_labels)= datasets.cifar10.load_data()\n",
        "#Normalize and scale the data down to be from 0---->1\n",
        "training_images, testing_images = training_images / 255, testing_images / 255"
      ],
      "metadata": {
        "id": "3EKH8kuECk94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cec036a-9aff-4355-ef76-4f626d6157ba",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #Creating a class names list athen visualising 16 of the images in the data set\n",
        "#so we can assing names to the labels (they are at firs numbers)\n",
        "class_names = ['Plane', 'Car', 'Bird', 'Cat',\"Deer\",'Dog','Frog',\"Horse\", 'ship', 'Truck' ]\n",
        "#now we will look at 16 images of the data set using a 4x4 grid\n",
        "for i in range(16):\n",
        "   plt.subplot(4,4,i+1) #that says that we have a 4x4 grid\n",
        "   plt.xticks([]) #those are for coordinates so we leave them empty because\n",
        "   plt.yticks([]) #we don't need them\n",
        "   plt.imshow(training_images[i], cmap=plt.cm.binary) #showing the images and giving them colors\n",
        "   plt.xlabel(class_names[training_labels[i][0]]) #puting a label under the image so we get the class name of that image\n",
        "\n",
        "plt.show() #the order to show the images"
      ],
      "metadata": {
        "id": "WRl9s4G7Ti9U",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building and training the model\n",
        "training_images = training_images[:20000] # we are reducing the amout of images\n",
        "training_labels = training_labels[:20000] # that we are feeding the neural network\n",
        "testing_images = testing_images[:4000] # and reducing the amount of testing images as well\n",
        "testing_labels = testing_labels[:4000]\n",
        "\n",
        "#Building the neural network\n",
        "model=models.Sequential() #we made a {Sequential} model\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu', input_shape=(32,32,3))) # this is an input layer that is a Convlutional Layer with 32 Neurons giving the activation function and the shape of the input\n",
        "model.add(layers.MaxPooling2D((2,2))) # this is a max pooling 2d layer , we us it after each convelutional layer to simplifie the result and reduce it to the icential information\n",
        "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64, (3,3), activation= 'relu'))\n",
        "model.add(layers.Flatten()) # we are here we are flatening the input by making it 1 dimencinal (making 10x10--->100)\n",
        "model.add(layers.Dense(64, activation=\"relu\"))\n",
        "model.add(layers.Dense(10, activation = 'softmax')) #outpu layer with 10 units (10 possible classification), we are using softmax tha scales all the results so the all add up to one (if you have 50, 70 ,60 it scale them to percenteges adding up to 1  )\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=10, validation_data=(testing_images, testing_labels))\n",
        "\n",
        "loss, accuracy = model.evaluate(testing_images, testing_labels)\n",
        "print(f\"Loss:{loss}\")\n",
        "print(f\"Accuracy:{accuracy}\")\n",
        "\n",
        "model.save('image_classifier.model')\n"
      ],
      "metadata": {
        "id": "isJ-aS1IYqHP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions= model.predict(testing_images)\n",
        "print(class_names[np.argmax(predictions[492])])\n",
        "plt.figure()\n",
        "plt.imshow(testing_images[492])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t97A8jnj8uYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image using cv2.imread\n",
        "file_path = r\"C:\\Users\\Lenovo i7\\Desktop\\photo\\horse1.jpg\"  # Verify this path is correct\n",
        "img = cv.imread(file_path)\n",
        "\n",
        "# Check if the image was loaded successfully\n",
        "if img is None:\n",
        "    print(f\"Error: Could not load image from {file_path}. Check the file path and ensure the image is not corrupted.\")\n",
        "else:\n",
        "    # Preprocess the image and make a prediction\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)  # Convert to RGB\n",
        "    img_array = np.array([img]) / 255.0  # Normalize pixel values\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    index = np.argmax(prediction)\n",
        "    print(f'Prediction is {class_names[index]}')\n",
        "\n",
        "    # Display the image (optional)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dgh3Yj7A8tM",
        "outputId": "1560e473-635a-488f-8e16-4ef953610fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not load image from C:\\Users\\Lenovo i7\\Desktop\\photo\\horse1.jpg. Check the file path and ensure the image is not corrupted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#file_path = r\"C:\\Users\\Lenovo i7\\Desktop\\photo\\plane.jpg\"\n",
        "img = cv.imread(r\"C:\\Users\\Lenovo i7\\Desktop\\photo\\plane.jpg\")\n",
        "#img = cv.cvtColor(img , cv.COLOR_BGR2RGB)\n",
        "\n",
        "#plt.imshow(img,cmap=plt.cm.binary)\n",
        "\n",
        "prediction = model.predict(np.array([img]) / 255)\n",
        "index = np.argmax(prediction)\n",
        "print(f'Predictions is {class_names[index]}')\n",
        "\n",
        "plt.show()\n",
        "#img = cv.imread(\"C:\\Users\\Lenovo i7\\Desktop\\photo\\horse1.jpg.jpg\")"
      ],
      "metadata": {
        "id": "3NWJrw6d4b2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.load_model('image_classifier.model')"
      ],
      "metadata": {
        "id": "TmwYDrZYMkQX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}